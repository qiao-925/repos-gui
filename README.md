# GitHub 仓库批量克隆脚本

集中管理所有 GitHub 仓库的工具仓库，融合**军事高地编号体系**与**批量克隆技术**，帮助开发者高效组织和管理代码仓库。

## 🎯 核心特点

### 🚀 批量克隆能力
- **双重并行**: 应用层同时克隆多个仓库（默认 5 并发）+ Git 层多连接传输（默认 8 连接），双重叠加大幅提升批量克隆效率
- **智能浅克隆**: 超过 300MB 的仓库自动使用浅克隆（`--depth 1`），仅克隆最新提交，大幅节省存储空间和克隆时间
  - **历史长仓库（10年以上、大量提交）**: 浅克隆效果显著，可减少 80-90% 的存储空间和克隆时间（例如：500MB → 50MB）
  - **新仓库（几个月历史、少量提交）**: 浅克隆效果有限，通常只能减少 10-20% 的空间
  - **策略说明**: 300MB 阈值能有效识别需要优化的仓库，在节省空间和保留历史之间取得平衡
- **高效组织**: 每个分组自动创建独立文件夹（组名 + 高地编号），清晰管理
- **自动重试**: 每个仓库克隆失败后立即重试3次（带间隔）

### ⚔️ 军事高地编号体系
- **独特命名**: 使用历史上著名高地编号（如 `597.9高地`、`382高地`）作为分组代号
- **集中注意力**: 军事比喻帮助开发者以"攻占高地"的心态专注管理项目
- **历史意义**: 每个编号背后都有真实的军事历史，增强记忆和识别度

## 🔧 前置要求

**必须安装 GitHub CLI**，这是使用本工具的前提条件：

1. 安装 [GitHub CLI](https://cli.github.com/)
2. 登录认证：
   ```bash
   gh auth login
   ```

## 🚀 使用流程

### 步骤 1：创建分类文档（AI 辅助 + 高地编号）

**在 Cursor 对话框中执行 PROMPT**

1. 打开 `GitHub 仓库分类 Prompt.md`，复制 prompt 模板
2. 在 Cursor 对话框中执行：`@GitHub 仓库分类 Prompt.md 执行当前prompt`
3. AI 会根据你的仓库列表自动分类，并为每个分组分配**高地编号**（如 `597.9高地`、`382高地`）
4. 检查分类是否合理，如需调整告诉 AI 你的修改意见
5. 确认满意后，告诉 AI "保存" 或 "持久化"，AI 会保存为 `REPO-GROUPS.md`

💡 **高地编号说明**：每个分组都会获得一个独特的高地编号（参考 `高地编号参考.md`），这些编号来自历史上著名的军事战役，帮助你以"攻占高地"的心态专注管理项目。

### 步骤 2：批量同步所有分组

完成分类后，运行脚本即可**自动同步所有分组**：

```bash
bash sync-groups-v2.sh
```

脚本会：
1. 自动列出所有可用分组
2. 自动同步所有分组下的仓库

💡 **克隆特点**：
- 自动检测已存在的仓库，跳过已克隆的仓库
- 每个分组自动创建独立文件夹（格式：`组名 (高地编号)`）
- 所有分组下的仓库会自动批量克隆（并行处理）
- **智能浅克隆**：超过 300MB 的仓库自动使用浅克隆（`--depth 1`），仅克隆最新提交，节省存储空间和克隆时间
  - **历史长短影响**：
    - **历史长仓库（10年以上、大量提交）**：浅克隆效果显著，可减少 80-90% 的存储空间和克隆时间
      - 例如：一个 10 年历史、1000+ 提交的仓库，完整克隆可能需要 500MB，浅克隆只需 50MB
      - 克隆时间从几分钟缩短到几十秒
    - **新仓库（几个月历史、少量提交）**：浅克隆效果有限，通常只能减少 10-20% 的空间
      - 例如：一个 3 个月历史、50 个提交的仓库，完整克隆 100MB，浅克隆可能只需 80MB
  - **策略合理性**：300MB 阈值能有效识别历史较长的仓库，这些仓库通常包含大量历史提交和对象，浅克隆效果最明显
- **仓库大小统计**：同步前自动统计所有仓库大小，显示总大小、大仓库列表等信息，让你心中有数
- 克隆失败自动重试3次，失败后自动清理不完整目录
- **性能优化**：内置 Git 网络优化配置，针对高带宽环境自动优化（详见下方"性能优化案例参考"）
- 大大提高效率，节省时间和存储空间

### 并行处理配置

**默认模式：并行执行**（同时处理多个仓库，充分利用网络带宽和设备性能）

#### 基本使用

```bash
# 使用默认配置（并行任务数 5，并行传输数 8）
bash sync-groups-v2.sh

# 查看帮助信息
bash sync-groups-v2.sh --help
```

#### 参数说明

| 参数 | 说明 | 默认值 | 示例 |
|------|------|--------|------|
| `-t <数字>` | 并行任务数：同时克隆多少个仓库 | 5 | `-t 10` |
| `-c <数字>` | 并行传输数：每个仓库克隆时的连接数 | 8 | `-c 16` |

#### 使用示例

```bash
# 只调整并行任务数（同时克隆 10 个仓库）
bash sync-groups-v2.sh -t 10

# 只调整并行传输数（每个仓库使用 16 个连接）
bash sync-groups-v2.sh -c 16

# 同时调整两个参数（推荐高带宽环境）
bash sync-groups-v2.sh -t 10 -c 16
```

💡 **性能说明**：
- **并行任务数（-t）**：控制脚本层面同时克隆多少个不同的仓库
- **并行传输数（-c）**：控制 Git 层面每个仓库克隆时使用多少个连接（需要 Git 2.32+）
- **两者叠加**：可以同时使用，效果叠加，充分利用网络带宽
- **Git 网络优化**：脚本会自动配置 Git 网络参数，针对高带宽环境优化（详见下方配置表）

#### Git 网络优化参数详情

脚本会自动配置以下 Git 参数以优化高带宽环境下的克隆速度：

| 参数 | 默认值 | 优化后值 | 说明 |
|------|--------|----------|------|
| `http.postBuffer` | 1MB | **500MB** | 增加 HTTP POST 缓冲区，减少网络往返次数，提升大仓库传输效率 |
| `http.lowSpeedLimit` | 1000 bytes/s | **0** | 禁用低速传输检测，避免高速网络被误判 |
| `http.lowSpeedTime` | 30秒 | **0** | 禁用低速传输超时，避免高速网络被误判 |
| `http.version` | HTTP/1.1 | **HTTP/2** | 使用 HTTP/2 协议，支持多路复用，更高效利用带宽 |
| `pack.windowMemory` | 256MB | **1GB** | 增加 pack 窗口内存，提升压缩和传输效率 |
| `pack.threads` | 自动 | **CPU核心数** | 显式使用多线程，充分利用多核 CPU 加速压缩和解压 |
| `core.compression` | 6 | **1** | 降低压缩级别（速度优先），在高速网络下减少压缩时间瓶颈 |

**优化效果**：这些配置可以显著提升克隆速度，特别是在高带宽（> 50Mbps）环境下效果明显。

#### 推荐配置

根据你的网络带宽选择合适的配置：

- **低带宽（< 10Mbps）**：`-t 3-5 -c 4-8`
- **中带宽（10-50Mbps）**：`-t 5-10 -c 8-12`
- **高带宽（50-200Mbps）**：`-t 10-15 -c 16-24`
- **超高带宽（> 200Mbps，如 300Mbps）**：`-t 15-20 -c 24-32`

#### 性能优化案例参考（300Mbps 带宽）

**环境信息**：
- 网络带宽：300Mbps
- 理论极限速度：约 40MB/s
- 默认配置速度：约 12MB/s（稳定）

**优化方案**（按推荐顺序测试）：

**方案一：保守优化（推荐首次使用）**
```bash
bash sync-groups-v2.sh -t 12 -c 20
```
- **预期效果**：速度提升至 18-22MB/s
- **特点**：稳定可靠，资源占用适中
- **适用场景**：首次优化测试，追求稳定性

**方案二：激进优化（方案一效果良好时使用）**
```bash
bash sync-groups-v2.sh -t 15 -c 24
```
- **预期效果**：速度提升至 25-30MB/s
- **特点**：性能提升明显，资源占用较高
- **适用场景**：方案一效果不错，想进一步提升速度

**方案三：极限优化（追求极致性能）**
```bash
bash sync-groups-v2.sh -t 18 -c 28
```
- **预期效果**：速度接近或达到 35-40MB/s（接近理论极限）
- **特点**：性能最大化，资源占用高
- **适用场景**：系统资源充足，追求极致速度

**测试建议**：
1. 按顺序测试：先试方案一，稳定后再试方案二，最后尝试方案三
2. 监控系统资源：观察 CPU、内存、网络使用率
3. 记录实际速度：使用脚本内置的速度监控功能查看实际效果

#### 常见问题与注意事项

**1. 连接超时或错误**

**症状**：克隆过程中出现连接超时、连接重置等错误

**可能原因**：
- 并行连接数过多，超过服务器限制
- 网络不稳定
- 防火墙或代理限制

**解决方法**：
- 降低并行传输数（`-c` 参数）：从 28 降到 24 或 20
- 降低并行任务数（`-t` 参数）：从 18 降到 15 或 12
- 检查网络连接稳定性
- 如果使用代理，检查代理配置

**2. CPU 或内存占用过高**

**症状**：系统卡顿，CPU 或内存使用率接近 100%

**解决方法**：
- 降低并行任务数（`-t` 参数）：减少同时克隆的仓库数量
- 降低并行传输数（`-c` 参数）：减少每个仓库的连接数
- 关闭其他占用资源的程序

**3. 速度未达到预期**

**可能原因**：
- 网络带宽实际低于预期
- GitHub 服务器限流
- 本地磁盘 I/O 成为瓶颈
- 仓库大小差异较大

**解决方法**：
- 使用脚本的速度监控功能，查看实际速度统计
- 检查网络带宽是否真的达到标称值
- 尝试不同时间段运行（避开高峰期）
- 检查磁盘读写速度（SSD 通常更快）

**4. 部分仓库克隆失败**

**症状**：部分仓库克隆失败，但其他仓库成功

**解决方法**：
- 脚本会自动重试 3 次，通常能自动恢复
- 如果持续失败，检查该仓库是否真的存在
- 检查是否有权限访问该仓库
- 查看错误日志，确认具体错误原因

**5. 速度统计不准确**

**症状**：速度统计显示为 0 或异常值

**可能原因**：
- Git 输出格式变化
- 仓库太小，速度信息未捕获

**解决方法**：
- 这是正常现象，小仓库可能无法准确捕获速度
- 速度统计仅统计成功克隆的仓库，失败的不计入
- 如果所有仓库都显示 0，可能是 Git 版本问题（需要 Git 2.32+）

**优化建议总结**：
- ✅ 从保守配置开始，逐步提升
- ✅ 监控系统资源，避免过载
- ✅ 记录实际速度，找到最佳配置
- ✅ 根据实际情况调整，不要盲目追求高参数
- ✅ 优先保证稳定性，再追求速度

**文件夹组织**：每个分组会自动创建对应的文件夹（格式：`组名 (高地编号)`，如 `Go-Practice (397.8号高地)`），该分组下的所有仓库会同步到对应的文件夹中，实现清晰的组织结构。

### 智能浅克隆功能

**功能说明**：对于超过 300MB 的仓库，脚本会自动使用浅克隆（`--depth 1`），仅克隆最新提交，不下载完整历史记录。

**适用场景**：
- ✅ **学习性项目**：历史很长但只需要最新代码的项目
- ✅ **大型项目**：占用空间大，但通常只需要最新版本
- ✅ **节省空间**：显著减少本地存储占用
- ✅ **节省时间**：浅克隆速度更快，无需下载完整历史

**工作原理**：
1. 扫描阶段：自动获取每个缺失仓库的大小（通过 GitHub API）
2. 统计显示：显示总大小、大仓库列表等信息
3. 智能决策：超过 300MB 的仓库自动使用 `--depth 1` 参数
4. 透明提示：浅克隆时会显示提示信息，告知用户使用了浅克隆

**示例输出**：
```
📦 仓库大小统计：
  - 总大小: 6.55 GB
  - ⚠️  超过 300MB 的仓库: 18 个（将使用浅克隆）
  - 🔴 超过 1GB 的仓库: 2 个

前 5 大仓库：
  1. toBeBetterJavaer - 1.96 GB
  2. elasticsearch - 1.22 GB
  ...

[克隆时]
使用浅克隆（仓库大小: 1.96 GB，仅克隆最新提交）
```

**注意事项**：
- ⚠️ 浅克隆的仓库不包含完整历史记录，如果需要查看历史，需要手动执行 `git fetch --unshallow`
- ⚠️ 浅克隆的仓库无法切换到历史提交（除非先执行 `git fetch --unshallow`）
- ✅ 对于大多数学习性项目，浅克隆完全够用，可以随时通过 `git fetch --unshallow` 获取完整历史

**如何获取完整历史**（如果需要）：
```bash
cd repos/分组名/仓库名
git fetch --unshallow  # 获取完整历史记录
```

---

## 📐 工作流与架构文档

### 核心设计原则

1. **单一职责**: 纯克隆工具，只负责批量克隆，不处理更新和删除
2. **全局性处理**: 先全局扫描所有差异，找出缺失的仓库，再统一执行克隆
3. **并行处理**: 默认并行处理，同时克隆多个仓库（默认 5 并发，可通过 `-t` 参数配置）
4. **并行传输**: 每个仓库克隆时使用多个连接（默认 8 连接，可通过 `-c` 参数配置，需要 Git 2.32+）
5. **智能重试**: 每个仓库失败后立即重试3次（带间隔），失败后自动清理不完整目录
6. **缓存优化**: 所有数据一次性加载到内存，避免重复 I/O 和 API 调用

### 主要工作流程

#### 完整执行流程（7个步骤）

```
开始 (main.sh)
  │
  ├─→ [1] 解析命令行参数
  │     └─ parse_args() [main.sh]
  │         ├─ 解析 -t 参数（并行任务数，默认 5）
  │         └─ 解析 -c 参数（并行传输数，默认 8）
  │
  ├─→ [2] 初始化克隆环境
  │     └─ initialize_sync() [sync-orchestration.sh]
  │         ├─ 检查配置文件存在性
  │         ├─ 创建 repos 目录
  │         ├─ 初始化 GitHub 连接 [github-api-query.sh]
  │         └─ 初始化统计变量 [stats.sh]
  │
  ├─→ [3] 初始化缓存系统
  │     ├─ init_config_cache() [cache.sh]
  │     │   └─ 解析 REPO-GROUPS.md，建立分组缓存
  │     └─ init_repo_cache() [cache.sh]
  │         └─ 批量获取所有远程仓库，建立名称映射
  │
  ├─→ [4] 获取所有分组用于克隆
  │     └─ get_all_group_names() [config.sh]
  │         └─ 从缓存中获取所有分组名称
  │
  ├─→ [5] 全局扫描差异，找出缺失的仓库
  │     └─ scan_global_diff() [diff-analysis.sh]
  │         ├─ 遍历所有分组和仓库
  │         ├─ 检查每个仓库的本地状态（检查 .git 目录）
  │         ├─ 获取每个缺失仓库的大小（用于统计和浅克隆决策）
  │         ├─ 分类：缺失 / 已存在（跳过）/ 跳过 / 不存在
  │         ├─ 显示仓库大小统计（总大小、大仓库列表等）
  │         └─ 存储到全局数组：
  │             ├─ global_repos_to_clone (缺失的，需要克隆的)
  │             └─ global_repo_sizes (仓库大小信息，用于浅克隆决策)
  │
  ├─→ [6] 执行批量克隆（并行处理）
  │     └─ execute_sync() [sync-orchestration.sh]
  │         ├─ 从 global_repos_to_clone 收集所有需要克隆的仓库
  │         ├─ 构建任务数组（格式：repo_full|repo_name|group_folder|group_name|global_index）
  │         └─ 并行执行克隆：
  │             └─ execute_parallel_repo_tasks() [sync-orchestration.sh]
  │                 └─ 并行调用 clone_repo() [repo-clone-update.sh]
  │                     ├─ 智能浅克隆：超过 300MB 的仓库自动使用 --depth 1
  │                     │   ├─ 历史长仓库（10年以上、大量提交）：效果显著，减少 80-90% 空间和时间
  │                     │   └─ 新仓库（几个月历史、少量提交）：效果有限，减少 10-20% 空间
  │                     ├─ 重试机制：失败后立即重试3次（间隔3秒）
  │                     ├─ 协议选择：优先 SSH，失败回退到 HTTPS
  │                     ├─ 并行传输：使用 --jobs 参数（默认 8 个连接）
  │                     └─ 自动清理：失败后删除不完整的目录
  │
  └─→ [7] 输出最终统计
        └─ print_final_summary() [stats.sh]
            ├─ 显示成功/失败统计
            ├─ 显示耗时统计
            └─ 显示速度统计（最大/最小/平均速度，仅统计成功克隆的仓库）
```

### 模块化架构

```
main.sh (主入口)
  │
  ├── lib/logger.sh (日志输出)
  ├── lib/utils.sh (工具函数)
  ├── lib/progress.sh (进度显示)
  ├── lib/config.sh (配置解析)
  ├── lib/cache.sh (缓存初始化)
  ├── lib/github-api-query.sh (GitHub API 查询 - 包含仓库大小查询)
  ├── lib/repo-clone-update.sh (仓库克隆操作 - 包含智能浅克隆)
  ├── lib/stats.sh (统计报告)
  ├── lib/diff-analysis.sh (差异分析 - 只检查缺失，包含大小统计)
  └── lib/sync-orchestration.sh (克隆编排)
```

**模块依赖关系**: logger/utils/progress → config/cache/github-api-query → repo-clone-update/stats/diff-analysis → sync-orchestration → main

**文件结构**: `main.sh` + `lib/*.sh` (11 个模块，总计 1749 行)

**核心函数**:
- `scan_global_diff()`: 扫描差异，找出缺失的仓库，获取仓库大小并显示统计
- `execute_sync()`: 执行批量克隆操作
- `clone_repo()`: 克隆单个仓库（智能浅克隆、带重试和清理，自动捕获速度信息）
- `get_repo_size()`: 获取仓库大小（KB），带缓存优化
- `format_repo_size()`: 格式化仓库大小显示（MB/GB）
- `execute_parallel_repo_tasks()`: 并行执行克隆任务
- `update_sync_statistics()`: 更新统计信息（包括速度统计）
- `print_final_summary()`: 输出最终统计（包括速度统计）

### 代码统计

#### 主要代码文件列表

| 文件 | 行数 | 功能说明 |
|------|------|----------|
| `main.sh` | 178 | **主入口**：解析命令行参数、初始化环境、协调各模块执行 |
| `lib/sync-orchestration.sh` | 263 | **克隆编排模块**：初始化克隆环境、执行批量克隆操作、并行任务管理 |
| `lib/diff-analysis.sh` | 233 | **差异分析模块**：全局扫描差异，找出缺失的仓库（只检查缺失，不检查更新） |
| `lib/repo-clone-update.sh` | 274 | **仓库克隆操作模块**：克隆仓库（带自动重试和清理不完整目录）、协议选择（SSH/HTTPS）、智能浅克隆 |
| `lib/cache.sh` | 151 | **缓存初始化模块**：初始化配置文件缓存、仓库名称缓存 |
| `lib/github-api-query.sh` | 161 | **GitHub API 查询模块**：获取 GitHub 用户名、初始化 GitHub 连接、查找仓库完整名称、获取仓库大小、格式化大小显示 |
| `lib/stats.sh` | 152 | **统计和报告模块**：初始化统计变量、更新统计信息（包括速度统计）、输出最终统计报告（包括速度统计：最大/最小/平均速度） |
| `lib/logger.sh` | 136 | **日志输出模块**：提供统一的日志输出功能（info/warning/error/success）、API 调用日志（带计时） |
| `lib/config.sh` | 108 | **配置解析模块**：解析配置文件、获取分组信息、高地编号管理 |
| `lib/progress.sh` | 35 | **进度显示模块**：提供简单的进度输出功能（带颜色） |
| `lib/utils.sh` | 18 | **工具函数模块**：提供字符串和数组转换的通用工具函数 |
| **总计** | **1749** | **11 个文件** |
